{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "from os import sysconf\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import random\n",
                "import sys\n",
                "import os\n",
                "\n",
                "path = 'Lyrics/lyrics_data/merged_lyrics.txt'\n",
                "artist_lyrics = open(path, 'r')\n",
                "lyrics = artist_lyrics.read()\n",
                "\n",
                "print(lyrics[:300])\n",
                "\n",
                "lyrics = lyrics[:1000000]\n",
                "\n",
                "print('Corpus length: ', len(lyrics))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Looking for some education\n",
                        "Made my way into the night\n",
                        "All that bullshit conversation\n",
                        "Baby, can't you read the signs? I won't bore you with the details, baby\n",
                        "I don't even wanna waste your time\n",
                        "Let's just say that maybe\n",
                        "You could help me ease my mind\n",
                        "I ain't Mr. Right But if you're looking for fast lo\n",
                        "Corpus length:  1000000\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "chars = sorted(list(set(lyrics)))\n",
                "print(chars)\n",
                "print('total chars: ', len(chars))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "['\\t', '\\n', ' ', '!', '\"', '&', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '¡', '¢', 'Ã', 'Þ', 'á', 'é', 'í', 'ð', 'ñ', 'ò', 'ó', 'ú', '–', '—', '‘', '’', '“', '”']\n",
                        "total chars:  100\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "# Create dictionary of characters to make an index for each char\n",
                "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
                "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
                "\n",
                "print(char_to_int)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "{'\\t': 0, '\\n': 1, ' ': 2, '!': 3, '\"': 4, '&': 5, \"'\": 6, '(': 7, ')': 8, '*': 9, ',': 10, '-': 11, '.': 12, '/': 13, '0': 14, '1': 15, '2': 16, '3': 17, '4': 18, '5': 19, '6': 20, '7': 21, '8': 22, '9': 23, ':': 24, ';': 25, '?': 26, 'A': 27, 'B': 28, 'C': 29, 'D': 30, 'E': 31, 'F': 32, 'G': 33, 'H': 34, 'I': 35, 'J': 36, 'K': 37, 'L': 38, 'M': 39, 'N': 40, 'O': 41, 'P': 42, 'Q': 43, 'R': 44, 'S': 45, 'T': 46, 'U': 47, 'V': 48, 'W': 49, 'X': 50, 'Y': 51, 'Z': 52, '[': 53, ']': 54, '`': 55, 'a': 56, 'b': 57, 'c': 58, 'd': 59, 'e': 60, 'f': 61, 'g': 62, 'h': 63, 'i': 64, 'j': 65, 'k': 66, 'l': 67, 'm': 68, 'n': 69, 'o': 70, 'p': 71, 'q': 72, 'r': 73, 's': 74, 't': 75, 'u': 76, 'v': 77, 'w': 78, 'x': 79, 'y': 80, 'z': 81, '¡': 82, '¢': 83, 'Ã': 84, 'Þ': 85, 'á': 86, 'é': 87, 'í': 88, 'ð': 89, 'ñ': 90, 'ò': 91, 'ó': 92, 'ú': 93, '–': 94, '—': 95, '‘': 96, '’': 97, '“': 98, '”': 99}\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "# Create sentence window\n",
                "\n",
                "seq_length = 50\n",
                "step = 1\n",
                "sentences = []\n",
                "next_chars = []\n",
                "\n",
                "#Create target and sentences window\n",
                "for i in range(0, len(lyrics) - seq_length, step):\n",
                "    sentences.append(lyrics[i: i+seq_length])\n",
                "    next_chars.append(lyrics[i+seq_length])\n",
                "\n",
                "sentences = np.array(sentences)\n",
                "next_chars = np.array(next_chars)\n",
                "\n",
                "print('Sentence Window:')\n",
                "print(sentences[:5])\n",
                "print('Target charaters')\n",
                "print (next_chars[:5])\n",
                "print('Number of sequences:', len(sentences))\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Sentence Window:\n",
                        "['Looking for some education\\nMade my way into the ni'\n",
                        " 'ooking for some education\\nMade my way into the nig'\n",
                        " 'oking for some education\\nMade my way into the nigh'\n",
                        " 'king for some education\\nMade my way into the night'\n",
                        " 'ing for some education\\nMade my way into the night\\n']\n",
                        "Target charaters\n",
                        "['g' 'h' 't' '\\n' 'A']\n",
                        "Number of sequences: 999950\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "# Transfer char to index\n",
                "\n",
                "def get_data(sentences, next_chars):\n",
                "    x = np.zeros((len(sentences),seq_length))\n",
                "    y = np.zeros(len(sentences))\n",
                "\n",
                "    length = len(sentences)\n",
                "    index = 0\n",
                "\n",
                "    for i in range(length):\n",
                "        sentence = sentences[i]\n",
                "        for t, char in enumerate(sentence):\n",
                "            x[i, t] = char_to_int[char]\n",
                "        \n",
                "        y[i] = char_to_int[next_chars[i]]\n",
                "\n",
                "    return x, y\n",
                "\n",
                "train_x, train_y = get_data(sentences, next_chars)\n",
                "\n",
                "print('Shape of training_x:', train_x.shape)\n",
                "print('Shape of training_y:', train_y.shape)\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Shape of training_x: (999950, 50)\n",
                        "Shape of training_y: (999950,)\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "source": [
                "# Building the model\n",
                "\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "import torch.optim as optim\n",
                "from torch.autograd import Variable\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "class Simple_LSTM(nn.Module):\n",
                "    def __init__(self, n_vocab, hidden_dim, embedding_dim, dropout=0.2):\n",
                "        super(Simple_LSTM, self).__init__()\n",
                "\n",
                "        self.hidden_dim = hidden_dim\n",
                "        self.embedding_dim = embedding_dim\n",
                "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, dropout = dropout, num_layers=2)\n",
                "        self.embeddings = nn.Embedding(n_vocab, embedding_dim)\n",
                "        self.fc = nn.Linear(hidden_dim, n_vocab)\n",
                "    def forward(self, seq_in):\n",
                "        #input should be (Sequnce_length,batchsize,hidden_layer), so we need to transpose the input\n",
                "        embedded = self.embeddings(seq_in.t())\n",
                "        lstm_out, _ = self.lstm(embedded)\n",
                "\n",
                "        ht = lstm_out[-1]\n",
                "        out = self.fc(ht)\n",
                "        return out"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "source": [
                "# Create DataLoader for mini-batch training\n",
                "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
                "\n",
                "x_train_tensor = torch.tensor(train_x, dtype=torch.long).to(device)\n",
                "y_train_tensor = torch.tensor(train_y, dtype=torch.long).to(device)\n",
                "\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "train = torch.utils.data.TensorDataset(x_train_tensor,y_train_tensor)\n",
                "train_loader = torch.utils.data.DataLoader(train, batch_size = 256)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "source": [
                "# Training\n",
                "model = Simple_LSTM(len(chars), 256, 256).to(device)\n",
                "optimizer = torch.optim.Adam(model.parameters(), lr = 0.002)\n",
                "loss_fn = torch.nn.CrossEntropyLoss()\n",
                "n_epochs = 40\n",
                "\n",
                "PATH = 'Lyrics/merged_net.pth'\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "source": [
                "#Training the network\n",
                "def train_net(n_epoch, loss_fn, optimizer, model, train_loader, device):\n",
                "\n",
                "    losses = []\n",
                "    eval_losses = []\n",
                "    running_loss = 0\n",
                "    eval_running_loss = 0\n",
                "\n",
                "    #loop through n_epoch times\n",
                "    for epoch in range(n_epoch):\n",
                "\n",
                "        for i, data in enumerate(train_loader, 0):\n",
                "\n",
                "            inputs, labels = data[0].to(device), data[1].to(device)\n",
                "\n",
                "            # Set model to train mode\n",
                "            model.train()\n",
                "            #Make predictions\n",
                "            pred = model(inputs)\n",
                "            \n",
                "            # Compute loss\n",
                "            loss = loss_fn(pred, labels)\n",
                "            # Compute gradients\n",
                "            loss.backward()\n",
                "            # Update params and zero grads\n",
                "            optimizer.step()\n",
                "            optimizer.zero_grad()\n",
                "            \n",
                "            # print statistics\n",
                "            running_loss += loss.item()\n",
                "            if i % len(train_loader) == len(train_loader)-1:    # print every len(train_loader) mini-batches\n",
                "                print('[%d, %5d] loss: %.5f' %(epoch + 1, i + 1, running_loss / len(train_loader)))\n",
                "                losses.append(running_loss/len(train_loader)) \n",
                "                running_loss = 0.0\n",
                "       \n",
                "    plt.subplot(1,2,1)\n",
                "    plt.plot(losses, label='Training loss')\n",
                "\n",
                "    print('Finished Training')\n",
                "    \n",
                "    torch.save(model.state_dict(), PATH)\n",
                "\n",
                "    print('Saved the Model!')"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "source": [
                "#train_net(n_epochs, loss_fn, optimizer, model, train_loader, device)\n",
                "model.load_state_dict(torch.load(PATH))\n"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "<All keys matched successfully>"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 10
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "source": [
                "# Function to choose next char for generated lyrics\n",
                "# We want some randomness so that the same char is not always picked\n",
                "\n",
                "def sample(preds, temperature=1.0):\n",
                "    \n",
                "    preds = np.asarray(preds).astype('float64')\n",
                "    \n",
                "    # Adds a lil bit of randomness\n",
                "    preds = np.log(preds) / temperature\n",
                "    exp_preds = np.exp(preds)\n",
                "    preds = exp_preds / np.sum(exp_preds)\n",
                "\n",
                "    probas = np.random.multinomial(1, preds, 1)\n",
                "\n",
                "    return np.argmax(probas)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "source": [
                "# Generate some lyrics\n",
                "#This must be 50 chars\n",
                "start_sentence = 'I am a cannabis man \\nGot a joint in each of my han'\n",
                "\n",
                "variance = 0.3\n",
                "generated = ''\n",
                "original = start_sentence\n",
                "window = start_sentence\n",
                "\n",
                "for i in range(800):\n",
                "    x = np.zeros((1, seq_length))\n",
                "    for t, char in enumerate(window):\n",
                "       #change input to vec of ints\n",
                "       # loop through current window and encode it to the vector x\n",
                "       x[0, t] = char_to_int[char]\n",
                "\n",
                "    # send x to the gpu to be fed into net\n",
                "    x_in = Variable(torch.LongTensor(x).to(device))\n",
                "    pred = model(x_in)\n",
                "    \n",
                "    # retrieve data from gpu and apply softmax\n",
                "    pred = np.array(F.softmax(pred, dim=1).data[0].cpu())\n",
                "    \n",
                "    #sample func adds a little but of randomness and returns the next char as int\n",
                "    next_index = sample(pred, variance)\n",
                "    #convert new int to char\n",
                "    next_char = int_to_char[next_index]\n",
                "\n",
                "    #add new char to generated lyrics\n",
                "    generated += next_char\n",
                "    \n",
                "    #shift window along to include new char and leave first char\n",
                "    window = window[1:] + next_char\n",
                "\n",
                "print(original + generated)\n",
                "    "
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "/tmp/ipykernel_3023/334539089.py:9: RuntimeWarning: divide by zero encountered in log\n",
                        "  preds = np.log(preds) / temperature\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "I am a cannabis man \n",
                        "Got a joint in each of my hand\n",
                        "There is no more to get and try to be all right\n",
                        "I'm so much true, I don't wanna, I know that trying to get the room town (One and there is no sunshine)\n",
                        "Oh, Jah la la la la la la la\n",
                        "Oh wo-wop, choo-wop, don' you get all the people and some on the sky\n",
                        "I know the right on the lights so much some of the right (when I got a soul)\n",
                        "And we're jammin' (Lord) (I'm glad)\n",
                        "(I want to get together)\n",
                        "Oh, like a back to some true\n",
                        "And then I'm gonna wake to the Lord is this songs (we're gonna be all right)\n",
                        "(I'm tryna go down) (I don't know why) (coming in) (Can't you get ang love)\n",
                        "(I'm gonna be alright) (I wanna) you told the sun\n",
                        "(Like the trult is a soul)\n",
                        "Oh, what you want to get together now!\n",
                        "(I'm gonna wake up the street)\n",
                        "And there is no sense in the train dem it seems to see\n",
                        "One thing I wanna go\n",
                        "There\n"
                    ]
                }
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.8.10",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.8.10 64-bit ('MLvenv': venv)"
        },
        "interpreter": {
            "hash": "3c5deedbfea70084e63f288ba49a2f9456761c977349528e54a40dbdea00cf01"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}